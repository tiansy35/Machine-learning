{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw1_solution.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"code","metadata":{"id":"JXCMO-KSHept"},"source":["import random \n","import numpy as np\n","import pandas as pd\n","\n","random.seed(42)  # don't change this line"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Asyzto_DKfBQ","outputId":"71909be5-1bcc-4cf3-f3b0-b49b3f32a0dd"},"source":["# Load all data tables\n","df = pd.read_csv('NHANES-diabetes-train.csv')\n","df_2 = pd.read_csv('NHANES-diabetes-train.csv')\n","df_3 = pd.read_csv('NHANES-diabetes-train.csv')\n","\n","# Output debugging info\n","print(df.shape)\n","df.head()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["(8140, 1812)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SEQN</th>\n","      <th>SDDSRVYR</th>\n","      <th>RIDSTATR</th>\n","      <th>RIAGENDR</th>\n","      <th>RIDAGEYR</th>\n","      <th>RIDAGEMN</th>\n","      <th>RIDRETH1</th>\n","      <th>RIDRETH3</th>\n","      <th>RIDEXMON</th>\n","      <th>RIDEXAGM</th>\n","      <th>...</th>\n","      <th>WHD080L</th>\n","      <th>WHD110</th>\n","      <th>WHD120</th>\n","      <th>WHD130</th>\n","      <th>WHD140</th>\n","      <th>WHQ150</th>\n","      <th>WHQ030M</th>\n","      <th>WHQ500</th>\n","      <th>WHQ520</th>\n","      <th>DIABETIC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>76195</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>18</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>1.0</td>\n","      <td>217.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>138.0</td>\n","      <td>18.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>76958</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>57</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>135.0</td>\n","      <td>115.0</td>\n","      <td>67.0</td>\n","      <td>150.0</td>\n","      <td>45.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>80248</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>29</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>125.0</td>\n","      <td>NaN</td>\n","      <td>160.0</td>\n","      <td>28.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>80213</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>5.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>76753</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>61</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>160.0</td>\n","      <td>160.0</td>\n","      <td>69.0</td>\n","      <td>180.0</td>\n","      <td>30.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 1812 columns</p>\n","</div>"],"text/plain":["    SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDRETH1  \\\n","0  76195         8         2         1        18       NaN         5   \n","1  76958         8         2         2        57       NaN         2   \n","2  80248         8         2         2        29       NaN         2   \n","3  80213         8         2         2         0       5.0         1   \n","4  76753         8         2         1        61       NaN         3   \n","\n","   RIDRETH3  RIDEXMON  RIDEXAGM  ...  WHD080L  WHD110  WHD120  WHD130  WHD140  \\\n","0         7       1.0     217.0  ...      NaN     NaN     NaN     NaN   138.0   \n","1         2       1.0       NaN  ...      NaN   135.0   115.0    67.0   150.0   \n","2         2       2.0       NaN  ...      NaN     NaN   125.0     NaN   160.0   \n","3         1       2.0       6.0  ...      NaN     NaN     NaN     NaN     NaN   \n","4         3       2.0       NaN  ...      NaN   160.0   160.0    69.0   180.0   \n","\n","   WHQ150  WHQ030M  WHQ500  WHQ520  DIABETIC  \n","0    18.0      NaN     NaN     NaN         0  \n","1    45.0      NaN     NaN     NaN         0  \n","2    28.0      NaN     NaN     NaN         0  \n","3     NaN      NaN     NaN     NaN         0  \n","4    30.0      NaN     NaN     NaN         0  \n","\n","[5 rows x 1812 columns]"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"UvNtFvGqKfDx","outputId":"e1162937-7610-4ffa-b93d-4e0a0b5bd0b4"},"source":["# Print information about the dataset\n","print('Percentage of instances with missing features:')\n","print(df.isnull().sum(axis=0)/df.shape[0])\n","print()\n","print('Class information:')\n","print(df['DIABETIC'].value_counts())"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Percentage of instances with missing features:\n","SEQN        0.000000\n","SDDSRVYR    0.000000\n","RIDSTATR    0.000000\n","RIAGENDR    0.000000\n","RIDAGEYR    0.000000\n","              ...   \n","WHQ150      0.407371\n","WHQ030M     0.853563\n","WHQ500      0.853563\n","WHQ520      0.853563\n","DIABETIC    0.000000\n","Length: 1812, dtype: float64\n","\n","Class information:\n","0    7447\n","1     693\n","Name: DIABETIC, dtype: int64\n"]}]},{"cell_type":"code","metadata":{"id":"QH3IMkmxm3E2"},"source":["# Trim dataframe\n","df = df.dropna(axis=1,thresh=7000) # Drop features with too many missing values\n","dfcorr = df.corr(method='pearson')\n","\n","# Select features according to correlation\n","for i in list(dfcorr):\n","    corrval = dfcorr[i].DIABETIC\n","    if corrval > -0.2 and corrval < 0.2:\n","        df = df.drop(columns=[i])\n","\n","# Manually drop irrelevant features\n","df = df.drop(columns=list(df.filter(regex='OHX')))\n","df = df.drop(columns='DIQ010')\n","df = df.drop(columns='SIAPROXY')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vhfk9CQoXfae"},"source":["## **Preprocessing**\n","\n","The first key step in any data modeling task is cleaning your dataset. Explore your dataset and figure out what sort of preprocessing is required. Good preprocessing can make or break your final model. So choose wisely.\n","\n","Some of the preprocessing steps that you can consider are :\n","\n","\n","*   One-hot encoding of variables\n","*   Missing value imputation\n","*   Removing outliers\n","*   Converting binary features into 0-1 representation\n","\n","\n","Feel free to reuse code you've already written in HW 0.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"2Fupod-VnNzu","outputId":"013c7502-2f79-441e-8607-b8a23ac42035"},"source":["# Impute missing values\n","print(df.isnull().sum(axis=0)/df.shape[0])\n","\n","df.BMXWT.fillna(df.BMXWT.mean(),inplace=True)\n","df.BMXBMI.fillna(df.BMXBMI.mean(),inplace=True)\n","df.BMXARMC.fillna(df.BMXARMC.mean(),inplace=True)\n","df.DIQ050.fillna(df.DIQ050.median(),inplace=True)\n","\n","# Remove outlier\n","df.describe()\n","\n","outlier = []\n","for i in range(len(df)):\n","    dfrow = df[i:i+1]\n","    if dfrow['DLQ050'].values > 2 or dfrow['HUQ010'].values > 5:\n","        outlier.append(i)\n","\n","df = df.drop(outlier) \n","\n","# Split data\n","X = df.drop(['DIABETIC'], axis=1)\n","y = df['DIABETIC']"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["SDDSRVYR    0.000000\n","RIDAGEYR    0.000000\n","DMDHHSZE    0.000000\n","DMDHRAGE    0.000000\n","BMXWT       0.044717\n","BMXBMI      0.107862\n","BMXARMC     0.084767\n","DIQ050      0.038698\n","DLQ050      0.135749\n","HUQ010      0.000000\n","DIABETIC    0.000000\n","dtype: float64\n"]}]},{"cell_type":"markdown","metadata":{"id":"F_HqomJOap0j"},"source":["## **Modeling**\n","\n","In this section, you are tasked with building a Decision Tree classifier to predict whether or not a patient has diabetes. The overall goal of this exercise is to investigate the dataset and develop features that would improve your model performance.\n","\n","To help with this process, we have provided the structure for two helper functions. These functions will help in tuning your model as well as validating your model's performance.\n","\n","Complete these two functions.\n","\n"]},{"cell_type":"code","metadata":{"id":"rsr6KV5wKfJB"},"source":["def cross_validated_accuracy(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n","    random.seed(random_seed)\n","    \"\"\"\n","       Args:\n","            DecisionTreeClassifier: An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")\n","            X: Input features\n","            y: Labels\n","            num_trials: Number of trials to run of cross validation\n","            num_folds: Number of folds (the \"k\" in \"k-folds\")\n","            random_seed: Seed for uniform execution (Do not change this) \n","\n","        Returns:\n","            cvScore: The mean accuracy of the cross-validation experiment\n","\n","        Notes:\n","            1. You may NOT use the cross-validation functions provided by Sklearn\n","    \"\"\"\n","    \n","    \n","    length = len(X.index)\n","    testlen = int(length/num_folds)\n","    accu1 = []\n","    accu2 = []\n","    \n","    for i in range(num_trials):\n","        # Shuffle the data set for every trial\n","        indexes = list(X.index)\n","        random.seed(random_seed)\n","        random.shuffle(indexes)\n","        X_shuffle = X.loc[indexes,:]\n","        y_shuffle = pd.Series(y,index = indexes)\n","        \n","        for j in range(num_folds):\n","            startind = j*testlen\n","            endind = (j+1)*testlen\n","            \n","            # Select training and testing folders\n","            X_test = X_shuffle[startind:endind]\n","            y_test = y_shuffle[startind:endind]\n","            X_train = X_shuffle[0:startind].append(X_shuffle[endind:length])\n","            y_train = y_shuffle[0:startind].append(y_shuffle[endind:length])\n","            \n","            clf = DecisionTreeClassifier.fit(X_train,y_train) \n","            \n","            y_pred = clf.predict(X_test) # Predict on the test folder\n","            \n","            accu2.append(1-((y_test != y_pred).sum())/len(y_pred)) # Calculate accuracy\n","        \n","        accu1.append(sum(accu2)/len(accu2))\n","        accu2 = []\n","    \n","    cvScore = sum(accu1)/len(accu1)\n","            \n","    return cvScore\n","\n","\n","#accuracy = cross_validated_accuracy(tree.DecisionTreeClassifier(criterion='entropy',ccp_alpha=0.03), X_3, y_3, 10, 10, 42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNISvwuvKvjP"},"source":["def automatic_dt_pruning(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n","    random.seed(random_seed)\n","    \"\"\"\n","      Returns the pruning parameter (i.e., ccp_alpha) with the highest cross-validated accuracy\n","\n","      Args:\n","            DecisionTreeClassifier  : An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")      \n","            X (Pandas.DataFrame)    : Input Features\n","            y (Pandas.Series)       : Labels\n","            num_trials              : Number of trials to run of cross validation\n","            num_folds               : Number of folds for cross validation (The \"k\" in \"k-folds\") \n","            random_seed             : Seed for uniform execution (Do not change this)\n","\n","\n","       Returns:\n","            ccp_alpha : Tuned pruning paramter with highest cross-validated accuracy\n","\n","       Notes:\n","            1. Don't change any other Decision Tree Classifier parameters other than ccp_alpha\n","            2. Use the cross_validated_accuracy function you implemented to find the cross-validated accuracy\n","\n","    \"\"\"\n","   \n","    # Set the range for ccp_alpha   \n","    step = 0.02\n","    maxccp = 0.4\n","    num = int(maxccp/step)\n","    result = []\n","    \n","    for i in range(num+1):\n","        ccp_test = i*step\n","        DecisionTreeClassifier.set_params(ccp_alpha = ccp_test)\n","        \n","        # Call the cross-validate function to compute accuracy\n","        accu_test = cross_validated_accuracy(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed)\n","        result.append([ccp_test, accu_test])\n","    \n","    # Find cpp_alpha with highest accuracy\n","    df = pd.DataFrame(result, columns = ['cppVal', 'Accuracy']) \n","    s = df['cppVal'][df.Accuracy == df.Accuracy.max()]\n","    ccp_alpha = s.mean()\n","    \n","    return ccp_alpha\n","\n","\n","#automatic_dt_pruning(tree.DecisionTreeClassifier(criterion='entropy'), X, y, 5, 5, 42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-LfgMo78b6SQ"},"source":["## **Tuning and Testing**\n","\n","With the helper functions and your processed dataset, build a Decision Tree classifier to classify Diabetic patients and tune it to maximize model performance.\n","\n","Once you are done with your modeling process, test your model on the test dataset and output your predictions in a file titled \"predictions.csv\", with one row per prediction."]},{"cell_type":"code","metadata":{"id":"BSVrMo_RcYti"},"source":["# Train a decision tree on the data\n","from sklearn import tree\n","\n","# Train and prune the decision tree\n","clf = tree.DecisionTreeClassifier(criterion='entropy')\n","\n","bestccp = automatic_dt_pruning(clf, X, y, 5, 10, 42)\n","clf.set_params(ccp_alpha = bestccp)\n","\n","# Compute the cross-validated accuracy\n","CV = cross_validated_accuracy(clf, X, y, 10, 10, 42)\n","print('The cross-validated accuracy is', CV)\n","\n","# Plot the tree\n","tree.plot_tree(clf)\n","\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wp3Azp2T9o1O","outputId":"e472db42-46e2-42d1-9249-7cb6f4ef5519"},"source":["# Predict on test data\n","X_test = pd.read_csv('NHANES-diabetes-test-unlabeled.csv')\n","\n","# Pre-process the test data\n","X_test = X_test[list(X.columns)]\n","\n","X_test.BMXWT.fillna(X_test.BMXWT.mean(),inplace=True)\n","X_test.BMXBMI.fillna(X_test.BMXBMI.mean(),inplace=True)\n","X_test.BMXARMC.fillna(X_test.BMXARMC.mean(),inplace=True)\n","X_test.DIQ050.fillna(X_test.DIQ050.median(),inplace=True)\n","X_test.DLQ050.fillna(X_test.DLQ050.median(),inplace=True)\n","\n","print(X_test.isnull().sum(axis=0)/df.shape[0])\n","\n","y_pred = clf.predict(X_test)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["SDDSRVYR    0.0\n","RIDAGEYR    0.0\n","DMDHHSZE    0.0\n","DMDHRAGE    0.0\n","BMXWT       0.0\n","BMXBMI      0.0\n","BMXARMC     0.0\n","DIQ050      0.0\n","DLQ050      0.0\n","HUQ010      0.0\n","dtype: float64\n"]}]},{"cell_type":"code","metadata":{"id":"dWIjjtmn9o1O"},"source":["# Save the predictions\n","y_data = pd.DataFrame(y_pred)\n","y_data.describe()\n","y_data.to_csv('predictions.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wgb1bchm9o1P","outputId":"739a00fc-401e-414a-f86c-a9922f217df2"},"source":["# Test on other features\n","\n","# Pre-process data\n","df_2 = df_2.dropna(axis=1,thresh=6000) # Drop features with too many missing values\n","print(df_2.isnull().sum(axis=0)/df.shape[0])\n","\n","df_2 = df_2.drop(columns='DIQ010')\n","\n","y_2 = df_2['DIABETIC']\n","X_2 = df_2.drop(['DIABETIC'], axis=1)\n","\n","randomfeat = np.random.randint(100,size=20)\n","X_2 = X_2.iloc[:,randomfeat]\n","X_2.fillna(0,inplace=True)\n","\n","# Train a decision tree on the data\n","from sklearn import tree\n","\n","# Train and prune the decision tree\n","clf = tree.DecisionTreeClassifier(criterion='entropy')\n","\n","bestccp = automatic_dt_pruning(clf, X_2, y_2, 5, 10, 42)\n","clf.set_params(ccp_alpha = bestccp)\n","\n","# Compute the cross-validated accuracy\n","CV = cross_validated_accuracy(clf, X_2, y_2, 10, 10, 42)\n","print('The cross-validated accuracy is', CV)\n","\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["SEQN         0.000000\n","SDDSRVYR     0.000000\n","RIDSTATR     0.000000\n","RIAGENDR     0.000000\n","RIDAGEYR     0.000000\n","               ...   \n","SMQ872       0.171646\n","SMQ874       0.007131\n","SMQ878       0.007131\n","SMAQUEX.x    0.003197\n","DIABETIC     0.000000\n","Length: 347, dtype: float64\n","The cross-validated accuracy is 0.9148648648648645\n"]}]},{"cell_type":"code","metadata":{"id":"XuYUY0W_9o1P","outputId":"e5849f91-3343-46ac-a0ec-29c5c16b2566"},"source":["# Test on other features\n","\n","df_3 = df_3[['RIDAGEYR', 'BMXWAIST', 'BMXHT',\n","       'LBXTC', 'BMXLEG', 'BMXWT',\n","       'BMXBMI', 'RIDRETH1', 'BPQ020',\n","       'ALQ120Q', 'DMDEDUC2', 'RIAGENDR',\n","       'INDFMPIR',\n","       'DIABETIC']]\n","\n","df_3 = df_3.dropna(axis=0)\n","\n","y_3 = df_3['DIABETIC']\n","X_3 = df_3.drop(['DIABETIC'], axis=1)\n","\n","# Train a decision tree on the data\n","from sklearn import tree\n","\n","# Train and prune the decision tree\n","clf = tree.DecisionTreeClassifier(criterion='entropy')\n","\n","bestccp = automatic_dt_pruning(clf, X_3, y_3, 5, 10, 42)\n","clf.set_params(ccp_alpha = bestccp)\n","\n","# Compute the cross-validated accuracy\n","CV = cross_validated_accuracy(clf, X_3, y_3, 10, 10, 42)\n","print('The cross-validated accuracy is', CV)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The cross-validated accuracy is 0.8603333333333334\n"]}]}]}